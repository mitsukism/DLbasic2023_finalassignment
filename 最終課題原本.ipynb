{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DL基礎最終課題"
      ],
      "metadata": {
        "id": "xFs9ixy8vAF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "第6回目の講義でRNNとLSTMの実装について学びました。その講義の中で紹介されたのはRNN, GRU, LSTM, Attentionでした。\n",
        "その中で演習でLSTMにフォーカスしてsentiment analysisタスクに取り組んだので、今回は演習で扱われなかった部分について自分の手でConvLSTMを実装し、実験しました。\n",
        "実験環境は以下の通りです。"
      ],
      "metadata": {
        "id": "vj7c7A4GvEGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###必要なライブラリのインポートと前処理"
      ],
      "metadata": {
        "id": "IJeBgC87rGeH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AP7Iwy3PFZ3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25641ec5-04f1-4e72-893f-b14045d77571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.7.0\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from sklearn.metrics import f1_score\n",
        "from einops.layers.torch import Rearrange\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "FmJixgI2lUBV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "zOTU31x9lXIa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j2xVBypuxc-M"
      },
      "outputs": [],
      "source": [
        "# torch.log(0)によるnanを防ぐための関数\n",
        "def torch_log(x):\n",
        "    return torch.log(torch.clamp(x, min=1e-10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXmoH5yuwNjs",
        "outputId": "73ad820e-0763-4174-9c0d-9e8b22b0f5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                            2.0.1+cu118\n",
            "torchaudio                       2.0.2+cu118\n",
            "torchdata                        0.6.1\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.15.2\n",
            "torchvision                      0.15.2+cu118\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9oN38u4fwNju"
      },
      "outputs": [],
      "source": [
        "train_iter = datasets.IMDB(split='train')\n",
        "\n",
        "train_iter, valid_iter = train_iter.random_split(\n",
        "    weights={\"train\": 0.8, \"valid\": 0.2},\n",
        "    seed=seed,\n",
        "    total_length=len(list(train_iter)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_Wl5lKUwNju",
        "outputId": "baaa95d1-81a8-4112-817b-20959272acf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "単語種数: 9937\n",
            "<unk>, <PAD>, <BOS>, <EOS>, i, am, curious, yellow, is, a, and, pretentious, steaming, pile, ., it, doesn, ', t, matter, what, one, s, political, views, are, because, this, film, can, hardly, be, taken, seriously, on, any, level, as, for, the, claim, that, frontal, male, nudity, an, automatic, ,, isn, true, ve, seen, films, with, granted, they, only, offer, some, fleeting, but, where, ?, nowhere, don, exist, same, goes, those, crappy, cable, shows, swinging, in, not, sight, indie, movies, like, brown, bunny, which, we, re, treated, to, site, of, vincent, johnson, trace, pink, visible, chloe, before, crying, (, or, ), matters\n"
          ]
        }
      ],
      "source": [
        "# 単語をスペースで区切り，!\"#$%&といった記号を除去する，すべて小文字化する，などの処理\n",
        "# https://pytorch.org/text/stable/data_utils.html\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "for label, line in train_iter:\n",
        "    counter.update(tokenizer(line))\n",
        "\n",
        "vocabulary = vocab(\n",
        "    counter,\n",
        "    min_freq=25,\n",
        "    specials=('<unk>', '<PAD>', '<BOS>', '<EOS>')\n",
        ")\n",
        "# <unk>をデフォルトに設定することにより，min_freq回以上出てこない単語は<unk>になる\n",
        "vocabulary.set_default_index(vocabulary['<unk>'])\n",
        "\n",
        "word_num = len(vocabulary)\n",
        "\n",
        "print(f\"単語種数: {word_num}\")\n",
        "print(*vocabulary.get_itos()[:100], sep=', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "waztS-jcwNjv"
      },
      "outputs": [],
      "source": [
        "def text_transform(_text, max_length=256):\n",
        "    # <BOS>と<EOS>の分 -2\n",
        "    text = [vocabulary[token] for token in tokenizer(_text)][:max_length - 2]\n",
        "    text = [vocabulary['<BOS>']] + text + [vocabulary['<EOS>']]\n",
        "\n",
        "    return text, len(text)\n",
        "\n",
        "def collate_batch(batch):\n",
        "   label_list, text_list, len_seq_list = [], [], []\n",
        "\n",
        "   for _label, _text in batch:\n",
        "      # torchtext==0.14.0まではnegativeは'neg', positiveは'pos'\n",
        "      # torchtext==0.15.1からはnegativeは1，positiveは2なので，-1して{0, 1}にする\n",
        "      label_list.append(_label - 1)\n",
        "\n",
        "      processed_text, len_seq = text_transform(_text)\n",
        "      text_list.append(torch.tensor(processed_text))\n",
        "      len_seq_list.append(len_seq)\n",
        "\n",
        "   return torch.tensor(label_list), pad_sequence(text_list, padding_value=1).T, torch.tensor(len_seq_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "   list(train_iter),\n",
        "   batch_size=batch_size,\n",
        "   shuffle=True,\n",
        "   collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "   list(valid_iter),\n",
        "   batch_size=batch_size,\n",
        "   shuffle=False,\n",
        "   collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "-zNihuaPSuNl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習関数の定義\n",
        "def train(\n",
        "    net,\n",
        "    optimizer,\n",
        "    n_epochs,\n",
        "):\n",
        "    for epoch in range(n_epochs):\n",
        "        losses_train = []\n",
        "        losses_valid = []\n",
        "\n",
        "        net.train()\n",
        "        n_train = 0\n",
        "        acc_train = 0\n",
        "        for label, line, len_seq in train_dataloader:\n",
        "            net.zero_grad()  # 勾配の初期化\n",
        "\n",
        "            t = label.to(device) # テンソルをGPUに移動\n",
        "            x = line.to(device) # ( batch, time )\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t * torch_log(y) + (1 - t) * torch_log(1 - y))\n",
        "\n",
        "            loss.backward()  # 誤差の逆伝播\n",
        "\n",
        "            optimizer.step()  # パラメータの更新\n",
        "\n",
        "            losses_train.append(loss.tolist())\n",
        "\n",
        "            n_train += t.size()[0]\n",
        "\n",
        "        # Valid\n",
        "        t_valid = []\n",
        "        y_pred = []\n",
        "        net.eval()\n",
        "        for label, line, len_seq in valid_dataloader:\n",
        "\n",
        "            t = label.to(device) # テンソルをGPUに移動\n",
        "            x = line.to(device)\n",
        "            len_seq.to(device)\n",
        "\n",
        "            h = net(x, torch.max(len_seq), len_seq)\n",
        "            y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
        "\n",
        "            pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n",
        "\n",
        "            t_valid.extend(t.tolist())\n",
        "            y_pred.extend(pred.tolist())\n",
        "\n",
        "            losses_valid.append(loss.tolist())\n",
        "\n",
        "        print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
        "            epoch,\n",
        "            np.mean(losses_train),\n",
        "            np.mean(losses_valid),\n",
        "            f1_score(t_valid, y_pred, average='macro')\n",
        "        ))"
      ],
      "metadata": {
        "id": "qmcVzxAvQbdJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5oyIOujKBy0"
      },
      "source": [
        "### 1. Recurrent Neural Network (RNN) によるIMDbのsentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xsrziOUkFX07"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, emb_dim, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding_matrix = nn.Parameter(torch.rand((vocab_size, emb_dim),\n",
        "                                                        dtype=torch.float))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.embedding(x, self.embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Qq01kXOFw3hD"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6 / (in_dim + hid_dim*2)\n",
        "        self.W = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "    def function(self, h, x):\n",
        "        return torch.tanh(torch.matmul(torch.cat([h, x], dim=1), self.W) + self.b)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, init_state=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state = init_state\n",
        "\n",
        "        if init_state is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state = self.function(state, x[i])\n",
        "            output = torch.cat([output, state.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpDGYK_rEcVS"
      },
      "outputs": [],
      "source": [
        "class SequenceTaggingNet(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(emb_dim, word_num)\n",
        "        self.rnn = RNN(emb_dim, hid_dim)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)\n",
        "        h = self.rnn(h, len_seq_max, init_state)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "        y = self.linear(h)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF1oS8scU160",
        "outputId": "fd2895b7-f696-4e21-ff70-f584e31dfc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0, Train Loss: 0.693, Valid Loss: 0.688, Validation F1: 0.527\n",
            "EPOCH: 1, Train Loss: 0.664, Valid Loss: 0.658, Validation F1: 0.595\n",
            "EPOCH: 2, Train Loss: 0.596, Valid Loss: 0.651, Validation F1: 0.625\n",
            "EPOCH: 3, Train Loss: 0.490, Valid Loss: 0.592, Validation F1: 0.718\n",
            "EPOCH: 4, Train Loss: 0.471, Valid Loss: 0.716, Validation F1: 0.631\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 5\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsXtYkNEm1Bh"
      },
      "source": [
        "### 2. Long short-term memory (LSTM)によるIMDbのsentiment analysis\n",
        "\n",
        "実装する式は次のようになります．($\\odot$は要素ごとの積)\n",
        "\n",
        "- 入力ゲート: $\\hspace{20mm}\\boldsymbol{i}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_i \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_i\\right)$\n",
        "- 忘却ゲート: $\\hspace{20mm}\\boldsymbol{f}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_f \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_f\\right)$\n",
        "- 出力ゲート: $\\hspace{20mm}\\boldsymbol{o}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_o \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_o\\right)$\n",
        "- セル:　　　 $\\hspace{20mm}\\boldsymbol{c}_t = \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\tanh \\left(\\boldsymbol{W}_c \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_c\\right)$\n",
        "- 隠れ状態: 　$\\hspace{20mm}\\boldsymbol{h}_t = \\boldsymbol{o}_t \\odot \\tanh \\left(\\boldsymbol{c}_t \\right)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0Zp__4EDBoJ3"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6/(in_dim + hid_dim*2)\n",
        "\n",
        "        self.W_i = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_i = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_f = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_f = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_o = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_o = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_c = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_c = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "    def function(self, state_c, state_h, x):\n",
        "        i = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_i) + self.b_i)\n",
        "        f = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_f) + self.b_f)\n",
        "        o = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_o) + self.b_o)\n",
        "        c = f*state_c + i*torch.tanh(torch.matmul(torch.cat([state_h, x], dim=1), self.W_c) + self.b_c)\n",
        "        h = o*torch.tanh(c)\n",
        "        return c, h\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, init_state_c=None, init_state_h=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state_c = init_state_c\n",
        "        state_h = init_state_h\n",
        "        if init_state_c is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_c = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "        if init_state_h is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_h = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state_h.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state_c, state_h = self.function(state_c, state_h, x[i])\n",
        "            output = torch.cat([output, state_h.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU-z8OtZu_cO"
      },
      "outputs": [],
      "source": [
        "class SequenceTaggingNet2(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(emb_dim, word_num)\n",
        "        self.lstm = LSTM(emb_dim, hid_dim)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)\n",
        "        h = self.lstm(h, len_seq_max, init_state)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "        y = self.linear(h)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAyD__D8vLvi",
        "outputId": "a4657e45-3890-486e-8a1f-a709fc9548f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0, Train Loss: 0.680, Valid Loss: 0.720, Validation F1: 0.373\n",
            "EPOCH: 1, Train Loss: 0.621, Valid Loss: 0.622, Validation F1: 0.682\n",
            "EPOCH: 2, Train Loss: 0.549, Valid Loss: 0.567, Validation F1: 0.696\n",
            "EPOCH: 3, Train Loss: 0.416, Valid Loss: 0.420, Validation F1: 0.814\n",
            "EPOCH: 4, Train Loss: 0.297, Valid Loss: 0.333, Validation F1: 0.862\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 5\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet2(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "h_size=[256, 128, 50]\\\n",
        "batch_size=128\\\n",
        "h_dim=50"
      ],
      "metadata": {
        "id": "dllLqjgZIzTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM(Peephole Connection)によるIMDbのsentiment analysis"
      ],
      "metadata": {
        "id": "qyPqkdf3HPV7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyaqVO8HPdC"
      },
      "source": [
        "実装する式\n",
        "\n",
        "- 入力ゲート: $\\hspace{20mm}\\boldsymbol{i}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_i \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\\\ \\boldsymbol {c}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_i\\right)$\n",
        "- 忘却ゲート: $\\hspace{20mm}\\boldsymbol{f}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_f \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\\\ \\boldsymbol{c}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_f\\right)$\n",
        "- 出力ゲート: $\\hspace{20mm}\\boldsymbol{o}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_o \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\\\ \\boldsymbol{c}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_o\\right)$\n",
        "- セル:　　　 $\\hspace{20mm}\\boldsymbol{c}_t = \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\tanh \\left(\\boldsymbol{W}_c \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_c\\right)$\n",
        "- 隠れ状態: 　$\\hspace{20mm}\\boldsymbol{h}_t = \\boldsymbol{o}_t \\odot \\tanh \\left(\\boldsymbol{c}_t \\right)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQW1pFtiG7WA"
      },
      "outputs": [],
      "source": [
        "class LSTM2(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6/(in_dim + hid_dim*2)\n",
        "\n",
        "        self.W_i = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim*2, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_i = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_f = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim*2, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_f = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_o = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim*2, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_o = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_c = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_c = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "    def function(self, state_c, state_h, x):\n",
        "        i = torch.sigmoid(torch.matmul(torch.cat([state_h, x, state_c], dim=1), self.W_i) + self.b_i)\n",
        "        f = torch.sigmoid(torch.matmul(torch.cat([state_h, x, state_c], dim=1), self.W_f) + self.b_f)\n",
        "        o = torch.sigmoid(torch.matmul(torch.cat([state_h, x, state_c], dim=1), self.W_o) + self.b_o)\n",
        "        c = f*state_c + i*torch.tanh(torch.matmul(torch.cat([state_h, x], dim=1), self.W_c) + self.b_c)\n",
        "        h = o*torch.tanh(c)\n",
        "        return c, h\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, init_state_c=None, init_state_h=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state_c = init_state_c\n",
        "        state_h = init_state_h\n",
        "        if init_state_c is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_c = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "        if init_state_h is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_h = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state_h.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state_c, state_h = self.function(state_c, state_h, x[i])\n",
        "            output = torch.cat([output, state_h.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBSQO-mBHA1Q"
      },
      "outputs": [],
      "source": [
        "class SequenceTaggingNet3(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(emb_dim, word_num)\n",
        "        self.lstm = LSTM2(emb_dim, hid_dim)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)\n",
        "        h = self.lstm(h, len_seq_max, init_state)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "        y = self.linear(h)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ffa5d0-e0e9-46a7-ffef-941f804cdeb8",
        "id": "IJGLuk2fHCzv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0, Train Loss: 0.690, Valid Loss: 0.701, Validation F1: 0.336\n",
            "EPOCH: 1, Train Loss: 0.677, Valid Loss: 0.647, Validation F1: 0.747\n",
            "EPOCH: 2, Train Loss: 0.580, Valid Loss: 0.476, Validation F1: 0.827\n",
            "EPOCH: 3, Train Loss: 0.413, Valid Loss: 0.392, Validation F1: 0.846\n",
            "EPOCH: 4, Train Loss: 0.361, Valid Loss: 0.368, Validation F1: 0.856\n"
          ]
        }
      ],
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 5\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet3(word_num, emb_dim, hid_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "train(net, optimizer, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TransformerによるIMDbのsentiment analysis"
      ],
      "metadata": {
        "id": "bad3ch9T3_pe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QDoSL5ojB-UG"
      },
      "outputs": [],
      "source": [
        "class LSTM3(nn.Module):\n",
        "    def __init__(self, in_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        glorot = 6/(in_dim + hid_dim*2)\n",
        "\n",
        "        self.W_i = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim*2, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_i = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_f = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim*2, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_f = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_o = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim*2, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_o = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "        self.W_c = nn.Parameter(torch.tensor(np.random.uniform(\n",
        "                        low=-np.sqrt(glorot),\n",
        "                        high=np.sqrt(glorot),\n",
        "                        size=(in_dim + hid_dim, hid_dim)\n",
        "                    ).astype('float32')))\n",
        "        self.b_c = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
        "\n",
        "    def function(self, state_c, state_h, x):\n",
        "        i = torch.sigmoid(torch.matmul(torch.cat([state_h, x, state_c], dim=1), self.W_i) + self.b_i)\n",
        "        f = torch.sigmoid(torch.matmul(torch.cat([state_h, x, state_c], dim=1), self.W_f) + self.b_f)\n",
        "        o = torch.sigmoid(torch.matmul(torch.cat([state_h, x, state_c], dim=1), self.W_o) + self.b_o)\n",
        "        c = f*state_c + i*torch.tanh(torch.matmul(torch.cat([state_h, x], dim=1), self.W_c) + self.b_c)\n",
        "        h = o*torch.tanh(c)\n",
        "        return c, h\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, init_state_c=None, init_state_h=None):\n",
        "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
        "        state_c = init_state_c\n",
        "        state_h = init_state_h\n",
        "        if init_state_c is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_c = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "        if init_state_h is None:  # 初期値を設定しない場合は0で初期化する\n",
        "            state_h = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
        "\n",
        "        size = list(state_h.unsqueeze(0).size())\n",
        "        size[0] = 0\n",
        "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
        "\n",
        "        if len_seq_max == 0:\n",
        "            len_seq_max = x.size(0)\n",
        "        for i in range(len_seq_max):\n",
        "            state_c, state_h = self.function(state_c, state_h, x[i])\n",
        "            output = torch.cat([output, state_c.unsqueeze(0)])  # 出力系列の追加\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tsaw_AI5SP18"
      },
      "outputs": [],
      "source": [
        "# Multi-Head Attentionの実装\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads, dim_head, dropout=0.):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        dim : int\n",
        "            入力データの次元数．埋め込み次元数と一致する．\n",
        "        heads : int\n",
        "            ヘッドの数．\n",
        "        dim_head : int\n",
        "            各ヘッドのデータの次元数．\n",
        "        dropout : float\n",
        "            Dropoutの確率(default=0.)．\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.dim_head = dim_head\n",
        "        inner_dim = dim_head * heads  # ヘッドに分割する前のQ, K, Vの次元数．self.dimと異なっても良い．\n",
        "        project_out = not (heads == 1 and dim_head == dim)  # headsが1，dim_headがdimと等しければ通常のSelf-Attention\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = math.sqrt(dim_head)  # ソフトマックス関数を適用する前のスケーリング係数(dim_k)\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)  # アテンションスコアの算出に利用するソフトマックス関数\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Q, K, Vに変換するための全結合層\n",
        "        self.to_q = nn.Linear(in_features=dim, out_features=inner_dim)\n",
        "        self.to_k = nn.Linear(in_features=dim, out_features=inner_dim)\n",
        "        self.to_v = nn.Linear(in_features=dim, out_features=inner_dim)\n",
        "\n",
        "        # dim != inner_dimなら線形層を入れる，そうでなければそのまま出力\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(in_features=inner_dim, out_features=dim),\n",
        "            nn.Dropout(dropout),\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        B: バッチサイズ\n",
        "        N: 系列長\n",
        "        D: データの次元数(dim)\n",
        "        \"\"\"\n",
        "        B, N, D = x.size()\n",
        "\n",
        "        # 入力データをQ, K, Vに変換する\n",
        "        # (B, N, dim) -> (B, N, inner_dim)\n",
        "        q = self.to_q(x)\n",
        "        k = self.to_k(x)\n",
        "        v = self.to_v(x)\n",
        "\n",
        "        # Q, K, Vをヘッドに分割する\n",
        "        # (B, N, inner_dim) -> (B, heads, N, dim_head)\n",
        "        q = rearrange(q, \"b n (h d) -> b h n d\", h=self.heads, d=self.dim_head)\n",
        "        k = rearrange(k, \"b n (h d) -> b h n d\", h=self.heads, d=self.dim_head)\n",
        "        v = rearrange(v, \"b n (h d) -> b h n d\", h=self.heads, d=self.dim_head)\n",
        "\n",
        "        # QK^T / sqrt(d_k)を計算する\n",
        "        # (B, heads, N, dim_head) x (B, heads, dim_head, N) -> (B, heads, N, N)\n",
        "        dots = torch.matmul(q, k.transpose(-2, -1)) / self.scale\n",
        "\n",
        "        # ソフトマックス関数でスコアを算出し，Dropoutをする\n",
        "        attn = self.attend(dots)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # softmax(QK^T / sqrt(d_k))Vを計算する\n",
        "        # (B, heads, N, N) x (B, heads, N, dim_head) -> (B, heads, N, dim_head)\n",
        "        out = torch.matmul(attn ,v)\n",
        "\n",
        "        # もとの形に戻す\n",
        "        # (B, heads, N, dim_head) -> (B, N, dim)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\", h=self.heads, d=self.dim_head)\n",
        "\n",
        "        # 次元が違っていればもとに戻して出力\n",
        "        # 表現の可視化のためにattention mapも返すようにしておく\n",
        "        return self.to_out(out), attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sZXoY0_tXRSM"
      },
      "outputs": [],
      "source": [
        "# Feed-Forward Networkの実装\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        dim : int\n",
        "            入力データの次元数．\n",
        "        hidden_dim : int\n",
        "            隠れ層の次元．\n",
        "        dropout : float\n",
        "            各全結合層の後のDropoutの確率(default=0.)．\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=dim, out_features=hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_features=hidden_dim, out_features=dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        (B, D) -> (B, D)\n",
        "        B: バッチサイズ\n",
        "        D: 次元数\n",
        "        \"\"\"\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oMs7TgXBRA6n"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, heads, dim_head, mlp_dim, dropout):\n",
        "        \"\"\"\n",
        "        TransformerのEncoder Blockの実装．\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        dim : int\n",
        "            埋め込みされた次元数．PatchEmbedのembed_dimと同じ値．\n",
        "        heads : int\n",
        "            Multi-Head Attentionのヘッドの数．\n",
        "        dim_head : int\n",
        "            Multi-Head Attentionの各ヘッドの次元数．\n",
        "        mlp_dim : int\n",
        "            Feed-Forward Networkの隠れ層の次元数．\n",
        "        dropout : float\n",
        "            Droptou層の確率p．\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn_ln = nn.LayerNorm(dim)  # Attention前のLayerNorm\n",
        "        self.attn = Attention(dim, heads, dim_head, dropout)\n",
        "        self.ffn_ln = nn.LayerNorm(dim)  # FFN前のLayerNorm\n",
        "        self.ffn = FFN(dim, mlp_dim, dropout)\n",
        "\n",
        "    def forward(self, x, return_attn=False):\n",
        "        \"\"\"\n",
        "        x: (B, N, dim)\n",
        "        B: バッチサイズ\n",
        "        N: 系列長\n",
        "        dim: 埋め込み次元\n",
        "        \"\"\"\n",
        "        y, attn = self.attn(self.attn_ln(x))\n",
        "        if return_attn:  # attention mapを返す（attention mapの可視化に利用）\n",
        "            return attn\n",
        "        x = y + x\n",
        "        out = self.ffn(self.ffn_ln(x)) + x\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceTaggingNet5(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim, heads, dim_head, mlp_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(emb_dim, word_num)\n",
        "        self.block = Block(hid_dim, heads, dim_head, mlp_dim, 0.)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)\n",
        "        h = self.block(h)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "\n",
        "        y = self.linear(h)\n",
        "        return y"
      ],
      "metadata": {
        "id": "CaqWvJs5LHQx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 5\n",
        "heads = 5\n",
        "dim_head = 10\n",
        "mlp_dim = 100\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet5(word_num, emb_dim, hid_dim, heads, dim_head, mlp_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "metadata": {
        "id": "KS7etguHK7Cc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(net, optimizer, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ZFmetGN1RT",
        "outputId": "ee08f10c-9ec0-4ab8-e538-70d61b1681ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0, Train Loss: 0.691, Valid Loss: 0.682, Validation F1: 0.501\n",
            "EPOCH: 1, Train Loss: 0.578, Valid Loss: 0.605, Validation F1: 0.725\n",
            "EPOCH: 2, Train Loss: 0.335, Valid Loss: 0.758, Validation F1: 0.674\n",
            "EPOCH: 3, Train Loss: 0.249, Valid Loss: 0.800, Validation F1: 0.675\n",
            "EPOCH: 4, Train Loss: 0.187, Valid Loss: 0.928, Validation F1: 0.650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM+TransformerによるIMDbのsentiment analysis"
      ],
      "metadata": {
        "id": "W3JFBIWYi9bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "改変\\\n",
        "TRansformerモデルのPositional Encoding部分をLSTMで置換\\\n",
        "参考文献：https://note.com/diatonic_codes/n/nab29c78bbf2e"
      ],
      "metadata": {
        "id": "XmzC_NfbLYyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceTaggingNet4(nn.Module):\n",
        "    def __init__(self, word_num, emb_dim, hid_dim, heads, dim_head, mlp_dim):\n",
        "        super().__init__()\n",
        "        self.emb = Embedding(emb_dim, word_num)\n",
        "        self.lstm = LSTM3(emb_dim, hid_dim)\n",
        "        self.block = Block(hid_dim, heads, dim_head, mlp_dim, 0.)\n",
        "        self.linear = nn.Linear(hid_dim, 1)\n",
        "\n",
        "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
        "        h = self.emb(x)\n",
        "        h = self.lstm(h, len_seq_max, init_state)\n",
        "        h = self.block(h)\n",
        "        if len_seq is not None:\n",
        "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
        "            h = h[len_seq - 1, list(range(len(x))), :]\n",
        "        else:\n",
        "            h = h[-1]\n",
        "\n",
        "        y = self.linear(h)\n",
        "        return y"
      ],
      "metadata": {
        "id": "39TIYX2BoHUQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 100\n",
        "hid_dim = 50\n",
        "n_epochs = 5\n",
        "heads = 5\n",
        "dim_head = 10\n",
        "mlp_dim = 100\n",
        "device = 'cuda'\n",
        "\n",
        "net = SequenceTaggingNet4(word_num, emb_dim, hid_dim, heads, dim_head, mlp_dim)\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    losses_train = []\n",
        "    losses_valid = []\n",
        "\n",
        "    net.train()\n",
        "    n_train = 0\n",
        "    acc_train = 0\n",
        "    for label, line, len_seq in train_dataloader:\n",
        "        net.zero_grad()  # 勾配の初期化\n",
        "\n",
        "        t = label.to(device) # テンソルをGPUに移動\n",
        "        x = line.to(device) # ( batch, time )\n",
        "        len_seq.to(device)\n",
        "\n",
        "        h = net(x, torch.max(len_seq), len_seq)\n",
        "        y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "        loss = -torch.mean(t * torch_log(y) + (1 - t) * torch_log(1 - y))\n",
        "\n",
        "        loss.backward()  # 誤差の逆伝播\n",
        "\n",
        "        optimizer.step()  # パラメータの更新\n",
        "\n",
        "        losses_train.append(loss.tolist())\n",
        "\n",
        "        n_train += t.size()[0]\n",
        "\n",
        "        # Valid\n",
        "    t_valid = []\n",
        "    y_pred = []\n",
        "    net.eval()\n",
        "    for label, line, len_seq in valid_dataloader:\n",
        "\n",
        "        t = label.to(device) # テンソルをGPUに移動\n",
        "        x = line.to(device)\n",
        "        len_seq.to(device)\n",
        "\n",
        "        h = net(x, torch.max(len_seq), len_seq)\n",
        "        y = torch.sigmoid(h).squeeze()\n",
        "\n",
        "        loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
        "\n",
        "        pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n",
        "\n",
        "        t_valid.extend(t.tolist())\n",
        "        y_pred.extend(pred.tolist())\n",
        "\n",
        "        losses_valid.append(loss.tolist())\n",
        "\n",
        "    print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
        "        epoch,\n",
        "        np.mean(losses_train),\n",
        "        np.mean(losses_valid),\n",
        "        f1_score(t_valid, y_pred, average='macro')\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8YbYobNrEds",
        "outputId": "5b8fb67e-89ad-4b9e-b0ec-e95228bc7622"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0, Train Loss: 0.699, Valid Loss: 0.689, Validation F1: 0.542\n",
            "EPOCH: 1, Train Loss: 0.655, Valid Loss: 0.680, Validation F1: 0.614\n",
            "EPOCH: 2, Train Loss: 0.416, Valid Loss: 0.842, Validation F1: 0.629\n",
            "EPOCH: 3, Train Loss: 0.263, Valid Loss: 1.012, Validation F1: 0.580\n",
            "EPOCH: 4, Train Loss: 0.208, Valid Loss: 0.832, Validation F1: 0.674\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IJeBgC87rGeH"
      ]
    },
    "kernelspec": {
      "display_name": "nam22",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4928584a19934792772f8bb8909943c28c334459e9e815fcc970144b80af4840"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}